{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cbb9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:98% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bd74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon, shape\n",
    "import asf_search as asf\n",
    "from datetime import datetime, date, timedelta\n",
    "from typing import List\n",
    "from pystac_client import Client, ItemSearch\n",
    "import geopandas as gpd\n",
    "from rasterio.crs import CRS\n",
    "import contextily as cx\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "from itertools import combinations\n",
    "import formatting as f\n",
    "import search as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c0f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4199885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cadence\n",
    "def get_cadence(results):\n",
    "    \n",
    "    cadence = ''\n",
    "    if len(results) == 0:\n",
    "        cadence = 'There is no coverage during this time'\n",
    "\n",
    "    else:\n",
    "        if len(results) == 1:\n",
    "            try:\n",
    "                cadence = 'Only one acquisition on ' + results.startTime[0]\n",
    "            except:\n",
    "                cadence = 'Only one acquisition on ' + results.start_datetime[0]\n",
    "\n",
    "        else:\n",
    "            cadence = []\n",
    "            for i in range(len(results) - 1):\n",
    "                try:\n",
    "                    cadence.append(str(f.asfsearch2datetime(results.startTime[i]) - f.asfsearch2datetime(results.startTime[i + 1])))\n",
    "                except:\n",
    "                    cadence.append(str(f.asfsearch2datetime(results.start_datetime[i + 1]) - f.asfsearch2datetime(results.start_datetime[i])))\n",
    "        \n",
    "    return cadence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445323ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage(sensor: List[str], aoi: Point, date: List[datetime] = None) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Sensor: choose sentinel1, sentinel2, landsat8\n",
    "    AOI: enter coordinates as Polygon object\n",
    "    date: leave as none if searching today, else enter time range as datetime tuple: datetime(YYYY,MM,DD)\n",
    "    \"\"\"\n",
    "    freq = {}\n",
    "    next_acq = {}\n",
    "    area = {}\n",
    "    \n",
    "    for sensor_name in sensor:\n",
    "        freq[sensor_name] = ''\n",
    "        next_acq[sensor_name] = ''\n",
    "        area[sensor_name] = ''\n",
    "        \n",
    "        if 'landsat8' in sensor_name.lower():\n",
    "            results = s.hls_search('landsat8', aoi, date)\n",
    "            df = f.format_results_for_hls(results)\n",
    "#             print('here')\n",
    "        elif 'sentinel1' in sensor_name.lower():\n",
    "            results = s.asf_search(aoi, date)\n",
    "            df = f.format_results_for_sent1(results)\n",
    "        elif 'sentinel2' in sensor_name.lower():\n",
    "            results = s.hls_search('sentinel2', aoi, date)\n",
    "            df = f.format_results_for_hls(results)\n",
    "        \n",
    "        df = df.dissolve(by='datetime').reset_index()\n",
    "        \n",
    "        # return cadence as string or list using get_cadence\n",
    "        freq[sensor_name] = get_cadence(df)\n",
    "        \n",
    "        # find next acquisition time, if search time is today then returns 'N/A'\n",
    "        if date == None:\n",
    "            next_acq[sensor_name] = 'N/A'\n",
    "            \n",
    "        else:\n",
    "            next_acq[sensor_name] = s.acq_search(sensor_name.lower(), aoi, date[1])\n",
    "        \n",
    "        # find area intersection for each sensor\n",
    "#         coords = [Polygon(c) for c in coords]\n",
    "#         area[sensor_name] = unary_union([a.intersection(b) for a, b in combinations(coords, 2)])\n",
    "        \n",
    "        if len(results) == 0:\n",
    "            area[sensor_name] = 0\n",
    "        else:\n",
    "            area[sensor_name] = df.geometry[0]\n",
    "            \n",
    "            if len(results) > 1:\n",
    "                \n",
    "                for i in range(len(coords) - 1):\n",
    "                    area[sensor_name] = area[sensor_name].intersection(df.geometry[i + 1])\n",
    "         \n",
    "    return freq, next_acq, area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06727188",
   "metadata": {},
   "source": [
    "### Polygons of areas of interest:\n",
    "\n",
    "Ridgecrest coordinates: Polygon([[-117.7167, 35.5909],[-117.6322, 35.5909],[-117.6322, 35.6452],[-117.7167, 35.6452],[-117.7167, 35.5909]])\n",
    "\n",
    "Wax lake delta: Polygon([[-91.4964, 29.4641],[-91.3849, 29.4641],[-91.3849, 29.5627],[-91.4964, 29.5627],[-91.4964, 29.4641]])\n",
    "\n",
    "Laurentides forest in Canada: Polygon([[-75.0327, 46.0832],[-74.8823, 46.0832],[-74.8823, 46.1914],[-75.0327, 46.1914],[-75.0327, 46.0832]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259c7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shapely and geodataframe files of areas of interest\n",
    "ridgecrest = Polygon([[-117.7167, 35.5909],[-117.6322, 35.5909],[-117.6322, 35.6452],[-117.7167, 35.6452],[-117.7167, 35.5909]])\n",
    "waxlake = Polygon([[-91.4964, 29.4641],[-91.3849, 29.4641],[-91.3849, 29.5627],[-91.4964, 29.5627],[-91.4964, 29.4641]])\n",
    "laurentides = Polygon([[-75.0327, 46.0832],[-74.8823, 46.0832],[-74.8823, 46.1914],[-75.0327, 46.1914],[-75.0327, 46.0832]])\n",
    "ridgecrest_df = f.shape2gdf(ridgecrest, 'ridgecrest')\n",
    "waxlake_df = f.shape2gdf(waxlake, 'waxlake')\n",
    "laurentides_df = f.shape2gdf(laurentides, 'laurentides')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52d34f48",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "freq1, next_acq1, area1 = get_coverage(['sentinel1','sentinel2','landsat8'],ridgecrest,[datetime(2022,1,1), datetime(2022,2,1)])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aa0136b",
   "metadata": {},
   "source": [
    "freq2, next_acq2, area2 = get_coverage(['sentinel1','sentinel2','landsat8'],waxlake,[datetime(2022,1,1), datetime(2022,2,1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab32791",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m freq3, next_acq3, area3 \u001b[38;5;241m=\u001b[39m \u001b[43mget_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentinel1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentinel2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlandsat8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlaurentides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2022\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2022\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mget_coverage\u001b[0;34m(sensor, aoi, date)\u001b[0m\n\u001b[1;32m     24\u001b[0m     results \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mhls_search(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel2\u001b[39m\u001b[38;5;124m'\u001b[39m, aoi, date)\n\u001b[1;32m     25\u001b[0m     df \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mformat_results_for_hls(results)\n\u001b[0;32m---> 27\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdissolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# return cadence as string or list using get_cadence\u001b[39;00m\n\u001b[1;32m     30\u001b[0m freq[sensor_name] \u001b[38;5;241m=\u001b[39m get_cadence(df)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ground-swath2/lib/python3.10/site-packages/geopandas/geodataframe.py:1686\u001b[0m, in \u001b[0;36mGeoDataFrame.dissolve\u001b[0;34m(self, by, aggfunc, as_index, level, sort, observed, dropna)\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;66;03m# Process non-spatial component\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mname, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1686\u001b[0m aggregated_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgroupby_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39magg(aggfunc)\n\u001b[1;32m   1687\u001b[0m aggregated_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m aggregated_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mto_flat_index()\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;66;03m# Process spatial component\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ground-swath2/lib/python3.10/site-packages/pandas/core/frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7707\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7709\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7710\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7711\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7715\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7718\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ground-swath2/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ground-swath2/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "freq3, next_acq3, area3 = get_coverage(['sentinel1','sentinel2','landsat8'],laurentides,[datetime(2022,1,1), datetime(2022,2,1)])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27a9c225",
   "metadata": {},
   "source": [
    "print(freq1['landsat8'])\n",
    "print(next_acq1['landsat8'])\n",
    "print(freq1['sentinel1'])\n",
    "print(next_acq1['sentinel1'])\n",
    "print(freq1['sentinel2'])\n",
    "print(next_acq1['sentinel2'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40e3d625",
   "metadata": {},
   "source": [
    "print(freq2['landsat8'])\n",
    "print(next_acq2['landsat8'])\n",
    "print(freq2['sentinel1'])\n",
    "print(next_acq2['sentinel1'])\n",
    "print(freq2['sentinel2'])\n",
    "print(next_acq2['sentinel2'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a185379",
   "metadata": {},
   "source": [
    "# print(area1['landsat8'])\n",
    "print(area1['sentinel1'])\n",
    "# print(area1['sentinel2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58102725",
   "metadata": {},
   "source": [
    "### Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq3['landsat8'])\n",
    "print(next_acq3['landsat8'])\n",
    "print(freq3['sentinel1'])\n",
    "print(next_acq3['sentinel1'])\n",
    "print(freq3['sentinel2'])\n",
    "print(next_acq3['sentinel2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee626c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = f.format_results_for_hls(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b6167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4295b90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dis = df.dissolve(by='datetime').reset_index()\n",
    "df_dis.start_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e78138",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadence = get_cadence_df(df_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d009541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "world.plot(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d97ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d355359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cont = world.dissolve(by='continent').reset_index()\n",
    "df_cont.iloc[:1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25060530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "world.dissolve(by='continent').plot(figsize=(10,10))\n",
    "# world.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d39e7",
   "metadata": {},
   "source": [
    "### The below cells are just for reminding what format the output results have"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66c1d93b",
   "metadata": {},
   "source": [
    "wkt = Polygon([[-117.7167, 35.5909],[-117.6322, 35.5909],[-117.6322, 35.6452],[-117.7167, 35.6452],[-117.7167, 35.5909]]).wkt\n",
    "opts = {\n",
    "    'platform': asf.PLATFORM.SENTINEL1,\n",
    "    'processingLevel': [asf.PRODUCT_TYPE.SLC],\n",
    "    'beamMode': [asf.BEAMMODE.IW],\n",
    "    'start': '2022-01-01T00:00:00Z',\n",
    "    'end': '2022-02-01T23:59:59Z'\n",
    "}\n",
    "results = asf.search(intersectsWith=wkt,**opts)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8f7de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = format_results_for_sent1(results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9f1960c",
   "metadata": {},
   "source": [
    "df.to_file('test.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ac7dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "api = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "hls_collections = ['HLSL30.v2.0']\n",
    "search_params = {\"collections\": hls_collections,\n",
    "                 \"bbox\": [-75.0327, 46.0832, -74.8823, 46.1914], # list of xmin, ymin, xmax, ymax\n",
    "                 \"datetime\": [datetime(2022,1,1), datetime(2022,2,1)],\n",
    "                 }\n",
    "search_hls = api.search(**search_params)\n",
    "hls_collection = search_hls.get_all_items()\n",
    "d = list(hls_collection)\n",
    "d[0].properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1469f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b83438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:2].to_file('test2.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba862107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(d)):\n",
    "    print(d[i].properties['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3384d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(area1['sentinel1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70c955",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns filled-in plot or outline of dictionary of polygons (or single polygon) with world map underneath\n",
    "def visual(area, outline = False):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 10)\n",
    "    \n",
    "    if type(area) == dict:\n",
    "        \n",
    "        color = ['blue','green','red']\n",
    "    \n",
    "        for num,frame in enumerate(area.keys()):\n",
    "            df = gpd.GeoDataFrame(geometry = [area[frame]],\n",
    "                                  crs = CRS.from_epsg(4326))\n",
    "            df_wm = df.to_crs(epsg = 3857)\n",
    "            if not outline:\n",
    "                df_wm.plot(ax = ax, alpha = .3, color=color[num], legend = True)\n",
    "            else:\n",
    "                df_wm.boundary.plot(ax = ax, color=color[num])\n",
    "            \n",
    "    elif type(area) == Polygon:\n",
    "        \n",
    "        df = gpd.GeoDataFrame(geometry = [area],\n",
    "                                  crs = CRS.from_epsg(4326))\n",
    "        df_wm = df.to_crs(epsg = 3857)\n",
    "        if not outline:\n",
    "            df_wm.plot(ax = ax, alpha = .3)\n",
    "        else:\n",
    "            df_wm.boundary.plot(ax = ax)\n",
    "    \n",
    "    cx.add_basemap(ax, zoom = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns plot of intersection of all polygons in input dictionary\n",
    "def find_overlap(area: dict, outline = False):\n",
    "    \n",
    "    for idx,key in enumerate(area.keys()):\n",
    "        if idx == 0:\n",
    "            overlap = area[key]\n",
    "        else:\n",
    "            overlap = overlap.intersection(area[key])\n",
    "            \n",
    "    visual(overlap, outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c885b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_overlap(area1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual(area1['sentinel1'],outline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual(area1['sentinel1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual(area1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0e3ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visual(area2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50b952",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visual(area3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace87b9",
   "metadata": {},
   "source": [
    "### Deprecated"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e88e740",
   "metadata": {},
   "source": [
    "Point(-121.5, 34.95)\n",
    "STAC_URL = 'https://earth-search.aws.element84.com/v0'\n",
    "api = Client.open(STAC_URL)\n",
    "url_collections = ['sentinel-s2-l2a-cogs']\n",
    "search_params = {\"collections\": url_collections,\n",
    "#                  \"bbox\": [-121.5, 34.95, -120.2, 36.25], # list of xmin, ymin, xmax, ymax\n",
    "                 \"datetime\": [datetime(2016,1,1), datetime(2016,2,1)],\n",
    "                 \"max_items\": 500}\n",
    "search_hls = api.search(**search_params)\n",
    "hls_collection = search_hls.get_all_items()\n",
    "d = list(hls_collection)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd348053",
   "metadata": {},
   "source": [
    "# for formatting the datetime object to asfsearch syntax\n",
    "def datetime2asfsearch(entered_date: datetime) -> str:\n",
    "    return datetime.strftime(entered_date,'%Y') + '-' + datetime.strftime(entered_date,'%m') + '-' + datetime.strftime(entered_date,'%d') + 'T' + datetime.strftime(entered_date,'%H') + ':' + datetime.strftime(entered_date,'%M') + ':' + datetime.strftime(entered_date,'%S') + 'Z'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fd1b965",
   "metadata": {},
   "source": [
    "# for formatting the asfsearch syntax to datetime object\n",
    "def asfsearch2datetime(entered_date: str) -> datetime:\n",
    "    try:\n",
    "        dtime = datetime.strptime(entered_date, '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    except:\n",
    "        dtime = datetime.strptime(entered_date, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    return dtime"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ac87d42",
   "metadata": {},
   "source": [
    "# reformat results from asf_search list to geodataframe\n",
    "def format_results_for_sent1(results: list) -> gpd.GeoDataFrame:\n",
    "    geometry = [shape(r.geojson()['geometry']) for r in results]\n",
    "    data = [r.properties for r in results]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = gpd.GeoDataFrame(df, geometry=geometry, crs=CRS.from_epsg(4326))\n",
    "\n",
    "    if df.empty:\n",
    "        warn('Dataframe is empty! Check inputs.')\n",
    "        return df\n",
    "\n",
    "    df['startTime'] = pd.to_datetime(df.startTime)\n",
    "    df['stopTime'] = pd.to_datetime(df.stopTime)\n",
    "    df['start_date'] = pd.to_datetime(df.startTime.dt.date)\n",
    "    df['start_date_str'] = df.start_date.dt.date.map(str)\n",
    "    df['pathNumber'] = df['pathNumber'].astype(int)\n",
    "    df.drop(columns=['browse'], inplace=True)\n",
    "    df = df.sort_values(by=['startTime', 'pathNumber']).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5813783",
   "metadata": {},
   "source": [
    "def format_results_for_hls(results: list) -> gpd.GeoDataFrame:\n",
    "    geometry = [shape(r.geometry) for r in results]\n",
    "    data = [r.properties for r in results]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = gpd.GeoDataFrame(df, geometry=geometry, crs=CRS.from_epsg(4326))\n",
    "\n",
    "    if df.empty:\n",
    "        warn('Dataframe is empty! Check inputs.')\n",
    "        return df\n",
    "    \n",
    "    df['startTime'] = pd.to_datetime(df.start_datetime.replace('Z',''))\n",
    "    df['stopTime'] = pd.to_datetime(df.end_datetime.replace('Z',''))\n",
    "    print(df.start_datetime)\n",
    "#     df['start_date'] = pd.to_datetime(df.start_datetime.replace('Z','').dt.date)\n",
    "#     df['start_date_str'] = df.start_datetime.replace('Z','').dt.date.map(str)\n",
    "    df = df.sort_values(by=['startTime']).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aea79dc",
   "metadata": {},
   "source": [
    "def shape2gdf(shape, filename: str) -> gpd.GeoDataFrame:\n",
    "    data = {}\n",
    "    data['coordinates'] = [shape.wkt]\n",
    "    data['coordinates'] = gpd.GeoSeries.from_wkt(data['coordinates'])\n",
    "    df = pd.DataFrame(data)\n",
    "    df = gpd.GeoDataFrame(df, geometry = 'coordinates', crs=CRS.from_epsg(4326))\n",
    "    df.to_file(filename + '.geojson',driver='GeoJSON')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af62989f",
   "metadata": {},
   "source": [
    "# for searching for sentinel2 and landsat8 data\n",
    "def hls_search(sensor: str, aoi: Polygon, date: List[datetime] = None):\n",
    "    STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "    api = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "    \n",
    "    if 'sentinel2' in sensor.lower():\n",
    "        hls_collections = ['HLSS30.v2.0']\n",
    "    elif 'landsat8' in sensor.lower():\n",
    "        hls_collections = ['HLSL30.v2.0']\n",
    "    \n",
    "    if date == None:\n",
    "        search_datetime = [datetime.combine(date.today(), datetime.min.time()), datetime.now()]\n",
    "    else:\n",
    "        search_datetime = date\n",
    "    \n",
    "    x, y = aoi.exterior.coords.xy\n",
    "    \n",
    "    search_params = {\n",
    "        \"collections\": hls_collections,\n",
    "        \"bbox\": [x[0],y[0],x[1],y[1]], # list of xmin, ymin, xmax, ymax\n",
    "        \"datetime\": search_datetime,\n",
    "    }\n",
    "    search_hls = api.search(**search_params)\n",
    "    hls_collection = search_hls.get_all_items()\n",
    "    d = list(hls_collection)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1127400e",
   "metadata": {},
   "source": [
    "# for searching sentinel1 data\n",
    "def asf_search(aoi: Polygon, date: datetime = None):\n",
    "    if date == None:\n",
    "        today = date.today()\n",
    "        start = str(today) + 'T00:00:00Z'\n",
    "        end = str(today) + 'T23:59:59Z'\n",
    "    else:\n",
    "        start = f.datetime2asfsearch(date[0])\n",
    "        end = f.datetime2asfsearch(date[1])\n",
    "\n",
    "    wkt = aoi.wkt\n",
    "    opts = {\n",
    "        'platform': asf.PLATFORM.SENTINEL1,\n",
    "        'processingLevel': [asf.PRODUCT_TYPE.SLC],\n",
    "        'beamMode': [asf.BEAMMODE.IW],\n",
    "        'start': start,\n",
    "        'end': end\n",
    "    }\n",
    "    results = asf.geo_search(intersectsWith=wkt,**opts)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce4da545",
   "metadata": {},
   "source": [
    "# find next acquisition date\n",
    "def acq_search(sensor_name: str, aoi: Polygon, date):\n",
    "    \n",
    "    # put arbitrary hard stop at 3 searches (15 days)\n",
    "    for rep in range(3):\n",
    "\n",
    "        if 'landsat8' in sensor_name.lower():\n",
    "            results = hls_search('landsat8', aoi, [date + timedelta(days = 5 * rep), date + timedelta(days = 5 * (rep + 1))])\n",
    "        elif 'sentinel1' in sensor_name.lower():\n",
    "            results = asf_search(aoi, [date + timedelta(days = 5 * rep), date + timedelta(days = 5 * (rep + 1))])\n",
    "        elif 'sentinel2' in sensor_name.lower():\n",
    "            results = hls_search('sentinel2', aoi, [date + timedelta(days = 5 * rep), date + timedelta(days = 5 * (rep + 1))])\n",
    "        \n",
    "        coords = [r.geometry['coordinates'][0] for r in results]\n",
    "            \n",
    "        if coords:\n",
    "            break\n",
    "    \n",
    "    # extract time of next acquisition\n",
    "    if coords:\n",
    "\n",
    "        try:\n",
    "            next_acq = results[0].properties['start_datetime']\n",
    "        except:\n",
    "            next_acq = results[-1].properties['startTime']\n",
    "\n",
    "    else:\n",
    "        next_acq = 'Search yielded no results'\n",
    "    \n",
    "    return next_acq"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2158747",
   "metadata": {},
   "source": [
    "# calculate cadence\n",
    "def get_cadence(results):\n",
    "    \n",
    "    cadence = ''\n",
    "    if len(results) == 0:\n",
    "        cadence = 'There is no coverage during this time'\n",
    "\n",
    "    else:\n",
    "        if len(results) == 1:\n",
    "            try:\n",
    "                cadence = 'Only one acquisition on ' + results[0].properties['startTime']\n",
    "            except:\n",
    "                cadence = 'Only one acquisition on ' + results[0].properties['start_datetime']\n",
    "\n",
    "        else:\n",
    "            cadence = []\n",
    "            for i in range(len(results) - 1):\n",
    "                try:\n",
    "                    cadence.append(str(f.asfsearch2datetime(results[i].properties['startTime']) - f.asfsearch2datetime(results[i + 1].properties['startTime'])))\n",
    "                except:\n",
    "                    cadence.append(str(f.asfsearch2datetime(results[i + 1].properties['start_datetime']) - f.asfsearch2datetime(results[i].properties['start_datetime'])))\n",
    "        \n",
    "    return cadence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
